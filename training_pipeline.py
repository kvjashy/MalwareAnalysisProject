import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import torch
import torch.nn as nn
from torch.utils.data import DataLoader, Dataset
from sklearn.metrics import roc_auc_score
from datasetcreation import MalwareDataset
from Malannet import MalanNet

def accuracy(outputs, labels):
    preds = torch.round(torch.sigmoid(outputs))  # Convert logits to binary predictions
    correct = (preds == labels).float()  # Convert int to float for division
    acc = correct.sum() / len(correct)  # Calculate accuracy
    return acc

def check_for_nans(tensor, name):
    if torch.isnan(tensor).any():
        print(f'NaN found in {name}')

def weights_init(m):
    if isinstance(m, nn.Conv2d) or isinstance(m, nn.Linear):
        nn.init.kaiming_normal_(m.weight)
        if m.bias is not None:
            nn.init.constant_(m.bias, 0)

data_path = "/home/kev/Documents/MalwareAnalysisProject/filtered_output_new.csv"
data = pd.read_csv(data_path)
X_train, X_val, y_train, y_val = MalwareDataset.splitting_data(data)

# Normalize the data
train_min = X_train.min()
train_max = X_train.max()

# Normalize the training data using the min and max of the training data
X_train = (X_train - train_min) / (train_max - train_min)

# Normalize the validation data using the same min and max of the training data
X_val = (X_val - train_min) / (train_max - train_min)

train_dataset = MalwareDataset(X_train, y_train)
val_dataset = MalwareDataset(X_val, y_val)

train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)
val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)

model = MalanNet()
model.apply(weights_init)

criterion = nn.BCEWithLogitsLoss()  # Binary Cross Entropy Loss with logits
optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-4)  # Lower the learning rate and add weight decay

num_epochs = 5
train_losses = []
val_losses = []
val_accuracies = []
val_aucs = []

# Training loop
for epoch in range(num_epochs):
    model.train()
    running_loss = 0.0
    for inputs, labels in train_loader:
        optimizer.zero_grad()
        outputs = model(inputs)
        loss = criterion(outputs, labels)
        loss.backward()

        # Clip gradients to prevent exploding gradients
        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=0.1)

        optimizer.step()
        running_loss += loss.item()

        # Print gradients for debugging
        for name, param in model.named_parameters():
            if param.grad is not None:
                print(f"Gradients for {name}: {param.grad.mean().item()}")
                check_for_nans(param.grad, name)

    avg_train_loss = running_loss / len(train_loader)
    train_losses.append(avg_train_loss)

    # Validation loop
    model.eval()
    val_loss = 0.0
    val_acc = 0.0
    all_labels = []
    all_outputs = []
    with torch.no_grad():
        for inputs, labels in val_loader:
            outputs = model(inputs)
            loss = criterion(outputs, labels)
            acc = accuracy(outputs, labels)
            val_loss += loss.item()
            val_acc += acc.item()
            all_labels.extend(labels.cpu().numpy())
            all_outputs.extend(torch.sigmoid(outputs).cpu().numpy())
    avg_val_loss = val_loss / len(val_loader)
    avg_val_acc = val_acc / len(val_loader)
    val_losses.append(avg_val_loss)
    val_accuracies.append(avg_val_acc)

    # Calculate AUC
    auc = roc_auc_score(all_labels, all_outputs)
    val_aucs.append(auc)

    print(f'Epoch {epoch+1}/{num_epochs}, '
          f'Train Loss: {avg_train_loss:.4f}, '
          f'Validation Loss: {avg_val_loss:.4f}, '
          f'Validation Accuracy: {avg_val_acc * 100:.2f}%, '
          f'Validation AUC: {auc:.4f}')

# Plotting training and validation loss
plt.figure(figsize=(12, 6))
plt.plot(train_losses, label='Training Loss')
plt.plot(val_losses, label='Validation Loss')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.legend()
plt.show()

# Plotting validation accuracy
plt.figure(figsize=(12, 6))
plt.plot(val_accuracies, label='Validation Accuracy')
plt.xlabel('Epochs')
plt.ylabel('Accuracy')
plt.legend()
plt.show()

# Plotting validation AUC
plt.figure(figsize=(12, 6))
plt.plot(val_aucs, label='Validation AUC')
plt.xlabel('Epochs')
plt.ylabel('AUC')
plt.legend()
plt.show()
